# app.py
import streamlit as st
import feedparser
import pandas as pd
from datetime import datetime, timedelta, timezone
from urllib.parse import quote_plus
import time

JST = timezone(timedelta(hours=9))
st.set_page_config(page_title="å ´æ‰€ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆGoogle News / è‡ªå‹•ã‚¯ã‚¨ãƒªï¼‰", page_icon="ğŸ“°", layout="wide")

# -------- utils
def xdaysago(x: int = 0) -> str:
    """JSTåŸºæº–ã§ x æ—¥å‰ï¼ˆx<0ã¯æœªæ¥ï¼‰ã®YYYY-MM-DD"""
    return (datetime.now(JST).date() - timedelta(days=x)).isoformat()

def _published_to_jst(entry):
    try:
        tt = entry.get("published_parsed")
        if not tt: return None
        epoch = time.mktime(tt)
        dt_utc = datetime.utcfromtimestamp(epoch).replace(tzinfo=timezone.utc)
        return dt_utc.astimezone(JST)
    except Exception:
        return None

def google_news_to_table(rss_url: str, limit: int = 50) -> pd.DataFrame:
    fp = feedparser.parse(rss_url)
    rows, seen = [], set()
    for e in fp.entries[:limit]:
        link = e.get("link", "")
        if not link or link in seen: continue
        seen.add(link)
        title = e.get("title", "")
        src = e.get("source", {})
        source = src.get("title") if isinstance(src, dict) else ""
        published_jst = _published_to_jst(e)
        rows.append({
            "title": title,
            "source": source,
            "published_jst": published_jst.strftime("%Y-%m-%d %H:%M") if published_jst else "",
            "link": link,
        })
    return pd.DataFrame(rows)

# -------- query builder
EVENT_TERMS = "ã‚¤ãƒ™ãƒ³ãƒˆ OR é–‹å‚¬ OR ã‚ªãƒ¼ãƒ—ãƒ³ OR ç¥­ã‚Š OR ä½“é¨“ä¼š OR ãƒ•ã‚§ã‚¹ OR å±•ç¤ºä¼š OR å±•"

def build_query(place: str) -> str:
    """ï¼ˆå ´æ‰€åï¼‰ANDï¼ˆã‚¤ãƒ™ãƒ³ãƒˆèªã®ORæŸï¼‰ã‚’è‡ªå‹•ç”Ÿæˆ"""
    place = place.strip()
    return f'({place}) AND ({EVENT_TERMS})'

def q_to_tb(place: str, add: str = "") -> tuple[pd.DataFrame, str, str]:
    """æ˜¨æ—¥+ä»Šæ—¥ã‚’å¯¾è±¡ã«RSSå–å¾—ã€‚DF, å®ŸURL, å®Ÿã‚¯ã‚¨ãƒªã‚’è¿”ã™"""
    yesterday = xdaysago(1)   # æ˜¨æ—¥
    tomorrow = xdaysago(-1)   # æ˜æ—¥ï¼ˆbeforeç”¨ï¼‰
    query = build_query(place)
    # ã”æŒ‡å®šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: after:{yesterday}+before:{tomorrow}+{query}
    q_param = f"after:{yesterday}+before:{tomorrow}+{quote_plus(query)}"
    rss_url = f"https://news.google.com/rss/search?q={q_param}&hl=ja&gl=JP&ceid=JP:ja{add}"
    df = google_news_to_table(rss_url).iloc[:20]
    return df, rss_url, query

# -------- UI
st.title("ğŸ“° å ´æ‰€ãƒ‹ãƒ¥ãƒ¼ã‚¹")
st.caption("é§…å/åœ°å â†’ ãã“ã«é–¢é€£ã—ãŸã‚¤ãƒ™ãƒ³ãƒˆé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¡¨ç¤º")

with st.sidebar:
    place = st.text_input("é§…åãƒ»åœ°åï¼ˆä¾‹ï¼šæ¸‹è°·é§… / æ±äº¬é§… / äº¬éƒ½å¸‚ï¼‰", value="æ¸‹è°·é§…")
    max_rows = st.slider("è¡¨ç¤ºä»¶æ•°", 10, 50, 20, 5)
    run = st.button("æ¤œç´¢ã™ã‚‹")

if run:
    if not place.strip():
        st.warning("é§…åãƒ»åœ°åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    df, rss_url, actual_query = q_to_tb(place)

    if df.empty:
        st.info("é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åœ°åã‚’åºƒåŸŸï¼ˆåŒº/å¸‚/çœŒï¼‰ã«ã™ã‚‹ãªã©ãŠè©¦ã—ãã ã•ã„ã€‚")
        st.stop()

    df = df.head(max_rows)

    st.subheader("é–¢é€£è¨˜äº‹")
    for _, row in df.iterrows():
        with st.container(border=True):
            title_line = f"**[{row['title']}]({row['link']})**"
            if row['source']:
                title_line += f" Â· {row['source']}"
            st.markdown(title_line)
            if row['published_jst']:
                st.write(f"ğŸ•’ {row['published_jst']}ï¼ˆJSTï¼‰")

    with st.expander("è¡¨ã§è¦‹ã‚‹"):
        st.dataframe(df.rename(columns={
            "title": "ã‚¿ã‚¤ãƒˆãƒ«", "source": "åª’ä½“", "published_jst": "å…¬é–‹(JST)", "link": "ãƒªãƒ³ã‚¯"
        }), use_container_width=True)

    st.markdown("**å®Ÿéš›ã«ä½¿ç”¨ã—ãŸRSS URL**")
    st.code(rss_url, language="text")
    
else:
    st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«é§…åï¼ˆã¾ãŸã¯åœ°åï¼‰ã‚’å…¥ã‚Œã¦æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚æ¤œç´¢èªã¯è‡ªå‹•ã§ã‚¤ãƒ™ãƒ³ãƒˆé–¢é€£èªã‚’å«ã‚€å½¢ã«çµ„ã¿ç«‹ã¦ã¾ã™ã€‚")
